{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":247030800,"sourceType":"kernelVersion"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tokenizers datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T14:10:57.250952Z","iopub.execute_input":"2025-06-23T14:10:57.251252Z","iopub.status.idle":"2025-06-23T14:11:03.055253Z","shell.execute_reply.started":"2025-06-23T14:10:57.251230Z","shell.execute_reply":"2025-06-23T14:11:03.054379Z"},"_kg_hide-output":true,"_kg_hide-input":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom datasets import load_dataset\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import WordLevel\nfrom tokenizers.trainers import WordLevelTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\n\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:33.863808Z","iopub.execute_input":"2025-06-24T10:57:33.864744Z","iopub.status.idle":"2025-06-24T10:57:36.251495Z","shell.execute_reply.started":"2025-06-24T10:57:33.864709Z","shell.execute_reply":"2025-06-24T10:57:36.250461Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def get_config():\n    return {\n        'batch_size': 32,  # Increased for better GPU utilization\n        'epochs': 4,      # Reduced for faster training\n        'lr': 1e-4,\n        'seq_len': 128,\n        'd_model': 384,\n        'lang_src': 'en',\n        'lang_tgt': 'fr',  # Changed to French for better dataset availability\n        'model_folder': 'weights',\n        'model_basename': 'tmodel_',\n        'preload': None,\n        'tokenizer_file': 'tokenizer_{0}.json',\n        'experiment_name': 'runs/tmodel'\n    }\n\ndef get_weight_file_path(config, epoch):\n    model_folder = config['model_folder']\n    model_basename = config['model_basename']\n    model_filename = f\"{model_basename}{epoch}.pt\"\n    return str(Path('.')/model_folder/model_filename)\n\nconfig = get_config()\nprint(\"Configuration:\", config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:37.658074Z","iopub.execute_input":"2025-06-24T10:57:37.658693Z","iopub.status.idle":"2025-06-24T10:57:37.666544Z","shell.execute_reply.started":"2025-06-24T10:57:37.658664Z","shell.execute_reply":"2025-06-24T10:57:37.665648Z"}},"outputs":[{"name":"stdout","text":"Configuration: {'batch_size': 32, 'epochs': 4, 'lr': 0.0001, 'seq_len': 128, 'd_model': 384, 'lang_src': 'en', 'lang_tgt': 'fr', 'model_folder': 'weights', 'model_basename': 'tmodel_', 'preload': None, 'tokenizer_file': 'tokenizer_{0}.json', 'experiment_name': 'runs/tmodel'}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class InputEmbeddings(nn.Module):\n    def __init__(self, d_model: int, vocab_size: int):\n        super().__init__()\n        self.d_model = d_model\n        self.vocab_size = vocab_size\n        self.embedding = nn.Embedding(vocab_size, d_model)\n\n    def forward(self, x):\n        return self.embedding(x) * math.sqrt(self.d_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:38.645207Z","iopub.execute_input":"2025-06-24T10:57:38.646067Z","iopub.status.idle":"2025-06-24T10:57:38.651213Z","shell.execute_reply.started":"2025-06-24T10:57:38.646036Z","shell.execute_reply":"2025-06-24T10:57:38.650281Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model: int, seq_len: int, dropout: float):\n        super().__init__()\n        self.seq_len = seq_len\n        self.d_model = d_model\n        self.dropout = nn.Dropout(dropout)\n\n        pe = torch.zeros(seq_len, d_model)\n        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.shape[1], :].requires_grad_(False)\n        return self.dropout(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:38.842084Z","iopub.execute_input":"2025-06-24T10:57:38.842525Z","iopub.status.idle":"2025-06-24T10:57:38.849845Z","shell.execute_reply.started":"2025-06-24T10:57:38.842493Z","shell.execute_reply":"2025-06-24T10:57:38.848909Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class LayerNormalization(nn.Module):\n    def __init__(self, eps: float = 1e-6):\n        super().__init__()\n        self.eps = eps\n        self.alpha = nn.Parameter(torch.ones(1))\n        self.bias = nn.Parameter(torch.zeros(1))\n\n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        std = x.std(dim=-1, keepdim=True)\n        return self.alpha * (x-mean) / (std + self.eps) + self.bias","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:38.997868Z","iopub.execute_input":"2025-06-24T10:57:38.998612Z","iopub.status.idle":"2025-06-24T10:57:39.004687Z","shell.execute_reply.started":"2025-06-24T10:57:38.998572Z","shell.execute_reply":"2025-06-24T10:57:39.003533Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, d_model: int, d_ff: int, dropout: float):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.linear1 = nn.Linear(d_model, d_ff)\n        self.linear2 = nn.Linear(d_ff, d_model)\n\n    def forward(self, x):\n        return self.linear2(self.dropout(torch.relu(self.linear1(x))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:40.932817Z","iopub.execute_input":"2025-06-24T10:57:40.933245Z","iopub.status.idle":"2025-06-24T10:57:40.942090Z","shell.execute_reply.started":"2025-06-24T10:57:40.933216Z","shell.execute_reply":"2025-06-24T10:57:40.941128Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_model: int, h: int, dropout: float):\n        super().__init__()\n        self.d_model = d_model\n        self.h = h\n        assert d_model % h == 0, \"d_model is not divisible by h\"\n        self.d_k = d_model // h\n        self.wq = nn.Linear(d_model, d_model)\n        self.wk = nn.Linear(d_model, d_model)\n        self.wv = nn.Linear(d_model, d_model)\n        self.wo = nn.Linear(d_model, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    @staticmethod\n    def attention(q, k, v, mask, dropout):\n        d_k = q.shape[-1]\n        attention_scores = (q @ k.transpose(-2, -1)) / math.sqrt(d_k)\n        if mask is not None:\n            fill = torch.finfo(attention_scores.dtype).min\n            attention_scores.masked_fill_(~mask, fill)\n        attention_scores = attention_scores.softmax(dim=-1)\n        if dropout is not None:\n            attention_scores = dropout(attention_scores)\n        return (attention_scores @ v), attention_scores\n\n    def forward(self, q, k, v, mask):\n        query = self.wq(q)\n        key = self.wk(k)\n        value = self.wv(v)\n\n        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n\n        x, self.attention_scores = MultiHeadAttention.attention(query, key, value, mask, self.dropout)\n        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n        return self.wo(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:41.151171Z","iopub.execute_input":"2025-06-24T10:57:41.151596Z","iopub.status.idle":"2025-06-24T10:57:41.166950Z","shell.execute_reply.started":"2025-06-24T10:57:41.151566Z","shell.execute_reply":"2025-06-24T10:57:41.165805Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class ResidualConnection(nn.Module):\n    def __init__(self, dropout: float):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.norm = LayerNormalization()\n\n    def forward(self, x, sublayer):\n        return x + self.dropout(sublayer(self.norm(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:41.332056Z","iopub.execute_input":"2025-06-24T10:57:41.332344Z","iopub.status.idle":"2025-06-24T10:57:41.337644Z","shell.execute_reply.started":"2025-06-24T10:57:41.332323Z","shell.execute_reply":"2025-06-24T10:57:41.336603Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self, self_attention: MultiHeadAttention, self_feed_forward: FeedForward, dropout: float):\n        super().__init__()\n        self.attention_block = self_attention\n        self.feed_forward_block = self_feed_forward\n        self.residuals = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n\n    def forward(self, x, src_mask):\n        x = self.residuals[0](x, lambda x: self.attention_block(x, x, x, src_mask))\n        x = self.residuals[1](x, self.feed_forward_block)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:41.463562Z","iopub.execute_input":"2025-06-24T10:57:41.463858Z","iopub.status.idle":"2025-06-24T10:57:41.469436Z","shell.execute_reply.started":"2025-06-24T10:57:41.463832Z","shell.execute_reply":"2025-06-24T10:57:41.468684Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, layers: nn.ModuleList):\n        super().__init__()\n        self.layers = layers\n        self.norm = LayerNormalization()\n\n    def forward(self, x, mask):\n        for layer in self.layers:\n            x = layer(x, mask)\n        return self.norm(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:41.639873Z","iopub.execute_input":"2025-06-24T10:57:41.640160Z","iopub.status.idle":"2025-06-24T10:57:41.645788Z","shell.execute_reply.started":"2025-06-24T10:57:41.640138Z","shell.execute_reply":"2025-06-24T10:57:41.644677Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, self_attention: MultiHeadAttention, cross_attention: MultiHeadAttention, self_feed_forward: FeedForward, dropout: float):\n        super().__init__()\n        self.attention_block = self_attention\n        self.cross_attention = cross_attention\n        self.feed_forward_block = self_feed_forward\n        self.residuals = nn.ModuleList([ResidualConnection(dropout) for _ in range(3)])\n\n    def forward(self, x, encoder_output, tgt_mask, src_mask):\n        x = self.residuals[0](x, lambda x: self.attention_block(x, x, x, tgt_mask))\n        x = self.residuals[1](x, lambda x: self.cross_attention(x, encoder_output, encoder_output, src_mask))\n        x = self.residuals[2](x, self.feed_forward_block)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:41.874182Z","iopub.execute_input":"2025-06-24T10:57:41.874493Z","iopub.status.idle":"2025-06-24T10:57:41.880781Z","shell.execute_reply.started":"2025-06-24T10:57:41.874470Z","shell.execute_reply":"2025-06-24T10:57:41.879823Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, layers: nn.ModuleList):\n        super().__init__()\n        self.layers = layers\n        self.norm = LayerNormalization()\n\n    def forward(self, x, encoder_output, tgt_mask, src_mask):\n        for layer in self.layers:\n            x = layer(x, encoder_output, tgt_mask, src_mask)\n        return self.norm(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:46.934779Z","iopub.execute_input":"2025-06-24T10:57:46.935128Z","iopub.status.idle":"2025-06-24T10:57:46.940999Z","shell.execute_reply.started":"2025-06-24T10:57:46.935101Z","shell.execute_reply":"2025-06-24T10:57:46.939827Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class ProjectionLayer(nn.Module):\n    def __init__(self, d_model: int, vocab_size: int):\n        super().__init__()\n        self.proj = nn.Linear(d_model, vocab_size)\n    \n    def forward(self, x):\n        return torch.log_softmax(self.proj(x), dim=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:47.329442Z","iopub.execute_input":"2025-06-24T10:57:47.330342Z","iopub.status.idle":"2025-06-24T10:57:47.335496Z","shell.execute_reply.started":"2025-06-24T10:57:47.330308Z","shell.execute_reply":"2025-06-24T10:57:47.334434Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, projection_layer: ProjectionLayer, tgt_pos: PositionalEncoding):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.src_embed = src_embed\n        self.tgt_embed = tgt_embed\n        self.src_pos = src_pos\n        self.tgt_pos = tgt_pos\n        self.projection = projection_layer\n\n    def encode(self, src, src_mask):\n        src = self.src_embed(src)\n        src = self.src_pos(src)\n        return self.encoder(src, src_mask)\n\n    def decode(self, tgt, encoder_output, src_mask, tgt_mask):\n        tgt = self.tgt_embed(tgt)\n        tgt = self.tgt_pos(tgt)\n        return self.decoder(tgt, encoder_output, tgt_mask, src_mask)\n    \n    def project(self, x):\n        return self.projection(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:47.754412Z","iopub.execute_input":"2025-06-24T10:57:47.755036Z","iopub.status.idle":"2025-06-24T10:57:47.761843Z","shell.execute_reply.started":"2025-06-24T10:57:47.755007Z","shell.execute_reply":"2025-06-24T10:57:47.760835Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int = 512, N: int = 6, h: int = 4, dropout: float = 0.1, d_ff: int = 1024):\n    src_embed = InputEmbeddings(d_model, src_vocab_size)\n    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n\n    encoder_blocks = []\n    for _ in range(N):\n        encoder_attention = MultiHeadAttention(d_model, h, dropout)\n        encoder_feedforward = FeedForward(d_model, d_ff, dropout)\n        encoder_block = EncoderBlock(encoder_attention, encoder_feedforward, dropout)\n        encoder_blocks.append(encoder_block)\n\n    decoder_blocks = []\n    for _ in range(N):\n        decoder_attention = MultiHeadAttention(d_model, h, dropout)\n        decoder_cross_attention = MultiHeadAttention(d_model, h, dropout)\n        decoder_feedforward = FeedForward(d_model, d_ff, dropout)\n        decoder_block = DecoderBlock(decoder_attention, decoder_cross_attention, decoder_feedforward, dropout)\n        decoder_blocks.append(decoder_block)\n\n    encoder = Encoder(nn.ModuleList(encoder_blocks))\n    decoder = Decoder(nn.ModuleList(decoder_blocks))\n    project_layer = ProjectionLayer(d_model, tgt_vocab_size)\n\n    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, project_layer, tgt_pos)\n\n    for p in transformer.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform_(p)\n    \n    return transformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:48.205668Z","iopub.execute_input":"2025-06-24T10:57:48.206022Z","iopub.status.idle":"2025-06-24T10:57:48.215028Z","shell.execute_reply.started":"2025-06-24T10:57:48.205995Z","shell.execute_reply":"2025-06-24T10:57:48.214076Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def causal_mask(size, device=None):\n    # returns a (1, size, size) boolean mask where (i,j) is True iff j <= i\n    m = torch.triu(torch.ones((size, size), dtype=torch.bool), diagonal=1)\n    mask = ~m\n    mask = mask.unsqueeze(0)\n    return mask.to(device) if device is not None else mask\n\n# -----------------------------------------------------------------------------\n# 3) DATASET\n# -----------------------------------------------------------------------------\nclass BilingualDataset(Dataset):\n    def __init__(self, raw_split, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len):\n        self.raw = raw_split\n        self.tok_src = tokenizer_src\n        self.tok_tgt = tokenizer_tgt\n        self.src_lang = src_lang\n        self.tgt_lang = tgt_lang\n        self.seq_len = seq_len\n        self.sos_id = tokenizer_src.token_to_id('[SOS]')\n        self.eos_id = tokenizer_src.token_to_id('[EOS]')\n        self.pad_id = tokenizer_src.token_to_id('[PAD]')\n\n    def __len__(self):\n        return len(self.raw)\n\n    def __getitem__(self, idx):\n        item = self.raw[idx]\n        src_txt = item['translation'][self.src_lang]\n        tgt_txt = item['translation'][self.tgt_lang]\n\n        src_ids = self.tok_src.encode(src_txt).ids\n        tgt_ids = self.tok_tgt.encode(tgt_txt).ids\n\n        # account for SOS/EOS\n        if len(src_ids) + 2 > self.seq_len or len(tgt_ids) + 1 > self.seq_len:\n            raise ValueError(\"Sentence too long\")\n\n        # build encoder_input: [SOS] + src_ids + [EOS] + PAD...\n        enc = [self.sos_id] + src_ids + [self.eos_id]\n        enc += [self.pad_id] * (self.seq_len - len(enc))\n        enc = torch.tensor(enc, dtype=torch.long)\n\n        # build decoder_input: [SOS] + tgt_ids + PAD...\n        dec = [self.sos_id] + tgt_ids\n        dec += [self.pad_id] * (self.seq_len - len(dec))\n        dec = torch.tensor(dec, dtype=torch.long)\n\n        # build label: tgt_ids + [EOS] + PAD...\n        lbl = tgt_ids + [self.eos_id]\n        lbl += [self.pad_id] * (self.seq_len - len(lbl))\n        lbl = torch.tensor(lbl, dtype=torch.long)\n\n        # masks: boolean\n        enc_mask = (enc != self.pad_id).unsqueeze(0).unsqueeze(0)  # (1,1,seq_len)\n        dec_mask = (dec != self.pad_id).unsqueeze(0).unsqueeze(0)  # (1,1,seq_len)\n        dec_mask = dec_mask & causal_mask(self.seq_len)          # causal\n\n        return {\n            'encoder_input': enc,\n            'decoder_input': dec,\n            'label':         lbl,\n            'encoder_mask':  enc_mask.bool(),\n            'decoder_mask':  dec_mask.bool(),\n            'src_text':      src_txt,\n            'tgt_text':      tgt_txt\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:53.375695Z","iopub.execute_input":"2025-06-24T10:57:53.376021Z","iopub.status.idle":"2025-06-24T10:57:53.387502Z","shell.execute_reply.started":"2025-06-24T10:57:53.375997Z","shell.execute_reply":"2025-06-24T10:57:53.386412Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def get_all_sentences(ds, lang):\n    for item in ds:\n        yield item['translation'][lang]\n\ndef get_or_build_tokenizer(config, ds, lang):\n    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n    if not Path.exists(tokenizer_path):\n        tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n        tokenizer.pre_tokenizer = Whitespace()\n        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n        tokenizer.save(str(tokenizer_path))\n    else:\n        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n    return tokenizer\n\ndef get_ds(config):\n    print(\"Loading dataset...\")\n    ds_raw = load_dataset('opus100', f\"{config['lang_src']}-{config['lang_tgt']}\", split='train')\n    \n    print(\"Building tokenizers...\")\n    tokenizer_src = get_or_build_tokenizer(config, ds_raw, config['lang_src'])\n    tokenizer_tgt = get_or_build_tokenizer(config, ds_raw, config['lang_tgt'])\n\n    print(\"Filtering dataset...\")\n    def filter_long_sentences(example):\n        src_ids = tokenizer_src.encode(example['translation'][config['lang_src']]).ids\n        tgt_ids = tokenizer_tgt.encode(example['translation'][config['lang_tgt']]).ids\n        return len(src_ids) + 2 <= config['seq_len'] and len(tgt_ids) + 1 <= config['seq_len']\n\n    ds_raw = ds_raw.filter(filter_long_sentences)\n    print(f\"Dataset size after filtering: {len(ds_raw)}\")\n\n    train_ds_size = int(0.9 * len(ds_raw))\n    val_ds_size = len(ds_raw) - train_ds_size\n\n    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n\n    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n\n    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:57:55.065586Z","iopub.execute_input":"2025-06-24T10:57:55.065969Z","iopub.status.idle":"2025-06-24T10:57:55.077305Z","shell.execute_reply.started":"2025-06-24T10:57:55.065940Z","shell.execute_reply":"2025-06-24T10:57:55.076303Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def greedy(model, src, src_mask, tokenizer_tgt, max_len, device):\n    # Unwrap DataParallel\n    real = model.module if hasattr(model, 'module') else model\n\n    sos = tokenizer_tgt.token_to_id('[SOS]')\n    eos = tokenizer_tgt.token_to_id('[EOS]')\n\n    # Encode once\n    enc_out = real.transformer.encode(src, src_mask)  # (1, T_src, d_model)\n\n    # Start with SOS\n    ys = torch.full((1, 1), sos, dtype=torch.long, device=device)\n\n    for _ in range(max_len - 1):\n        seq_l = ys.size(1)\n        dec_mask = causal_mask(seq_l, device)  # (1, seq_l, seq_l)\n        logits = real( src, ys, src_mask, dec_mask )  # (1, seq_l, V)\n        nxt = logits[:, -1].argmax(-1, keepdim=True)  # (1,1)\n        ys = torch.cat([ys, nxt], dim=1)\n        if nxt.item() == eos:\n            break\n\n    return ys  # (1, L)\n\ndef run_validation(model, val_loader, tokenizer_tgt, max_len, device, print_fn, num_examples=2):\n    model.eval()\n    seen = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            # Expect batch size 1 for clarity\n            src      = batch['encoder_input'].to(device).long()\n            src_mask = batch['encoder_mask'].to(device)\n            assert src.size(0) == 1, \"Please use batch_size=1 for validation\"\n\n            gen = greedy(model, src, src_mask, tokenizer_tgt, max_len, device)\n            src_txt  = tokenizer_tgt.decode(src.squeeze(0).tolist())\n            ref_txt  = batch['tgt_text'][0]      # assuming your val dataset provides this\n            pred_txt = tokenizer_tgt.decode(gen.squeeze(0).tolist())\n\n            print_fn('-'*80)\n            print_fn(f\"SRC:       {src_txt}\")\n            print_fn(f\"REFERENCE: {ref_txt}\")\n            print_fn(f\"PREDICTED: {pred_txt}\")\n\n            seen += 1\n            if seen >= num_examples:\n                break\n    print_fn(\"Validation complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T10:58:09.000409Z","iopub.execute_input":"2025-06-24T10:58:09.000760Z","iopub.status.idle":"2025-06-24T10:58:09.010642Z","shell.execute_reply.started":"2025-06-24T10:58:09.000734Z","shell.execute_reply":"2025-06-24T10:58:09.009798Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class Seq2SeqModel(nn.Module):\n    def __init__(self, transformer):\n        super().__init__()\n        self.transformer = transformer\n\n    def forward(self, src, tgt, src_mask, tgt_mask):\n        # Encode → Decode → Project\n        enc_out = self.transformer.encode(src, src_mask)\n        dec_out = self.transformer.decode(tgt, enc_out, src_mask, tgt_mask)\n        return self.transformer.project(dec_out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:04:50.050876Z","iopub.execute_input":"2025-06-24T11:04:50.051234Z","iopub.status.idle":"2025-06-24T11:04:50.057979Z","shell.execute_reply.started":"2025-06-24T11:04:50.051210Z","shell.execute_reply":"2025-06-24T11:04:50.056918Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\n       \ndef train_model(config):\n    # Setup\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    Path(config['model_folder']).mkdir(parents=True, exist_ok=True)\n\n    # Data\n    print(\"Loading data...\")\n    train_dl, val_dl, tok_src, tok_tgt = get_ds(config)\n\n    # Model build\n    print(\"Building model...\")\n    core = build_transformer(\n        tok_src.get_vocab_size(),\n        tok_tgt.get_vocab_size(),\n        config['seq_len'], config['seq_len'],\n        config['d_model']\n    )\n    model = Seq2SeqModel(core)\n\n    # Multi‐GPU\n    if torch.cuda.device_count() > 1:\n        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n        model = nn.DataParallel(model)\n\n    model = model.cuda()\n    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n    loss_fn = nn.CrossEntropyLoss(\n        ignore_index=tok_src.token_to_id(\"[PAD]\"),\n        label_smoothing=0.1\n    ).cuda()\n\n    scaler     = GradScaler()\n    accum_steps = config.get('accum_steps', 1)\n\n    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    print(\"Starting training...\")\n\n    for epoch in range(1, config['epochs']+1):\n        model.train()\n        total_loss = 0.0\n        loop = tqdm(train_dl, desc=f\"Epoch {epoch}/{config['epochs']}\",\n                    mininterval=1.0, miniters=100)\n\n        optimizer.zero_grad()\n        for batch_idx, batch in enumerate(loop):\n            # Prepare (keep inputs on CPU)\n            src       = batch['encoder_input'].long()\n            tgt       = batch['decoder_input'].long()\n            src_mask  = batch['encoder_mask']\n            tgt_mask  = batch['decoder_mask']\n            labels    = batch['label'].long()\n\n            # Mixed‐precision forward\n            with autocast():\n                logits = model(src, tgt, src_mask, tgt_mask)  # (B, T, V)\n                loss   = loss_fn(\n                    logits.view(-1, tok_tgt.get_vocab_size()),\n                    labels.view(-1).cuda()\n                ) / accum_steps\n\n            # Backward + step (scaled)\n            scaler.scale(loss).backward()\n            if (batch_idx + 1) % accum_steps == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n\n            total_loss += loss.item() * accum_steps\n            loop.set_postfix({\n                \"loss\":     f\"{loss.item()*accum_steps:.3f}\",\n                \"avg_loss\": f\"{(total_loss/(batch_idx+1)):.3f}\"\n            })\n\n        avg_loss = total_loss / len(train_dl)\n        print(f\"Epoch {epoch} done — avg loss: {avg_loss:.4f}\")\n\n        # Validation (only need one GPU to print)\n        print(\"Running validation...\")\n        run_validation(model, val_dl, tok_tgt, config['seq_len'], device, print, num_examples=3)\n\n        # Checkpoint (unwrap real model if DataParallel)\n        real = model.module if hasattr(model, 'module') else model\n        ckpt = {\n            'epoch': epoch,\n            'model_state_dict': real.transformer.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'avg_loss': avg_loss\n        }\n        fn = get_weight_file_path(config, epoch)\n        torch.save(ckpt, fn)\n        print(f\"Saved checkpoint: {fn}\")\n\n    print(\"Training complete!\")\n    return model\n\n\n\nif __name__ == '__main__':\n    model = train_model(config)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-06-23T14:35:38.825259Z","iopub.execute_input":"2025-06-23T14:35:38.826304Z","iopub.status.idle":"2025-06-23T21:44:34.192778Z","shell.execute_reply.started":"2025-06-23T14:35:38.826268Z","shell.execute_reply":"2025-06-23T21:44:34.192079Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CHECKPOINT = \"/kaggle/usr/lib/transformer_from_scratch/weights/tmodel_4.pt\"\nSRC_TOKENIZER = \"/kaggle/usr/lib/transformer_from_scratch/tokenizer_en.json\"\nTGT_TOKENIZER = \"/kaggle/usr/lib/transformer_from_scratch/tokenizer_fr.json\"\nSEQ_LEN = 128\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# --- Load tokenizers ---\ntokenizer_src = Tokenizer.from_file(SRC_TOKENIZER)\ntokenizer_tgt = Tokenizer.from_file(TGT_TOKENIZER)\n\n# --- Build model & load weights ---\nmodel = build_transformer(\n    src_vocab_size=tokenizer_src.get_vocab_size(),\n    tgt_vocab_size=tokenizer_tgt.get_vocab_size(),\n    src_seq_len=SEQ_LEN, tgt_seq_len=SEQ_LEN,\n    d_model=384, N=6, h=4, dropout=0.1, d_ff=1024\n).to(DEVICE)\nckpt = torch.load(CHECKPOINT, map_location=DEVICE)\nmodel.load_state_dict(ckpt[\"model_state_dict\"])\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:02:01.933005Z","iopub.execute_input":"2025-06-24T11:02:01.933329Z","iopub.status.idle":"2025-06-24T11:02:03.718644Z","shell.execute_reply.started":"2025-06-24T11:02:01.933308Z","shell.execute_reply":"2025-06-24T11:02:03.717432Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Transformer(\n  (encoder): Encoder(\n    (layers): ModuleList(\n      (0-5): 6 x EncoderBlock(\n        (attention_block): MultiHeadAttention(\n          (wq): Linear(in_features=384, out_features=384, bias=True)\n          (wk): Linear(in_features=384, out_features=384, bias=True)\n          (wv): Linear(in_features=384, out_features=384, bias=True)\n          (wo): Linear(in_features=384, out_features=384, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (feed_forward_block): FeedForward(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear1): Linear(in_features=384, out_features=1024, bias=True)\n          (linear2): Linear(in_features=1024, out_features=384, bias=True)\n        )\n        (residuals): ModuleList(\n          (0-1): 2 x ResidualConnection(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (norm): LayerNormalization()\n          )\n        )\n      )\n    )\n    (norm): LayerNormalization()\n  )\n  (decoder): Decoder(\n    (layers): ModuleList(\n      (0-5): 6 x DecoderBlock(\n        (attention_block): MultiHeadAttention(\n          (wq): Linear(in_features=384, out_features=384, bias=True)\n          (wk): Linear(in_features=384, out_features=384, bias=True)\n          (wv): Linear(in_features=384, out_features=384, bias=True)\n          (wo): Linear(in_features=384, out_features=384, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (cross_attention): MultiHeadAttention(\n          (wq): Linear(in_features=384, out_features=384, bias=True)\n          (wk): Linear(in_features=384, out_features=384, bias=True)\n          (wv): Linear(in_features=384, out_features=384, bias=True)\n          (wo): Linear(in_features=384, out_features=384, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (feed_forward_block): FeedForward(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear1): Linear(in_features=384, out_features=1024, bias=True)\n          (linear2): Linear(in_features=1024, out_features=384, bias=True)\n        )\n        (residuals): ModuleList(\n          (0-2): 3 x ResidualConnection(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (norm): LayerNormalization()\n          )\n        )\n      )\n    )\n    (norm): LayerNormalization()\n  )\n  (src_embed): InputEmbeddings(\n    (embedding): Embedding(30000, 384)\n  )\n  (tgt_embed): InputEmbeddings(\n    (embedding): Embedding(30000, 384)\n  )\n  (src_pos): PositionalEncoding(\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (tgt_pos): PositionalEncoding(\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (projection): ProjectionLayer(\n    (proj): Linear(in_features=384, out_features=30000, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"model = Seq2SeqModel(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:05:13.773479Z","iopub.execute_input":"2025-06-24T11:05:13.773831Z","iopub.status.idle":"2025-06-24T11:05:13.778249Z","shell.execute_reply.started":"2025-06-24T11:05:13.773802Z","shell.execute_reply":"2025-06-24T11:05:13.777387Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def translate(text: str) -> str:\n    # 1) Tokenize and add special tokens\n    ids = tokenizer_src.encode(text).ids\n    ids = [tokenizer_src.token_to_id(\"[SOS]\")] + ids + [tokenizer_src.token_to_id(\"[EOS]\")]\n    # 2) Pad or truncate to SEQ_LEN\n    if len(ids) < SEQ_LEN:\n        ids += [tokenizer_src.token_to_id(\"[PAD]\")] * (SEQ_LEN - len(ids))\n    else:\n        ids = ids[:SEQ_LEN]\n    src = torch.tensor([ids], dtype=torch.long, device=DEVICE)\n\n    # 3) Build encoder mask\n    src_mask = (src != tokenizer_src.token_to_id(\"[PAD]\")).unsqueeze(1).unsqueeze(2)\n\n    # 4) Greedy decode\n    with torch.no_grad():\n        pred_ids = greedy(model, src, src_mask, tokenizer_tgt, SEQ_LEN, DEVICE)\n\n    # 5) Strip at EOS and decode\n    out = pred_ids.squeeze(0).tolist()\n    if tokenizer_tgt.token_to_id(\"[EOS]\") in out:\n        out = out[: out.index(tokenizer_tgt.token_to_id(\"[EOS]\")) ]\n    return tokenizer_tgt.decode(out).strip()\n\n# ─── Try it out ───────────────────────────────────────────────────────────────\nwhile True:\n    inp = input(\"Enter your english text\")\n    if inp.lower() == 'exit':\n        break\n    fr = translate(inp)\n    print(\"EN →\", inp)\n    print(\"FR →\", fr, \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:12:58.151307Z","iopub.execute_input":"2025-06-24T11:12:58.151699Z","iopub.status.idle":"2025-06-24T11:14:38.538001Z","shell.execute_reply.started":"2025-06-24T11:12:58.151673Z","shell.execute_reply":"2025-06-24T11:14:38.536759Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your english text France is a beautiful place to visit. I currently reside in India\n"},{"name":"stdout","text":"EN → France is a beautiful place to visit. I currently reside in India\nFR → La France est un endroit magnifique pour visiter . Je vis en Inde \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your english text How are you today\n"},{"name":"stdout","text":"EN → How are you today\nFR → Comment tu es aujourd ' hui \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your english text Merci\n"},{"name":"stdout","text":"EN → Merci\nFR → Merci . \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your english text Bonjur\n"},{"name":"stdout","text":"EN → Bonjur\nFR →  \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your english text How many people died yesterday\n"},{"name":"stdout","text":"EN → How many people died yesterday\nFR → Combien de gens sont morts hier \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your english text My name is Aniketh Reddy\n"},{"name":"stdout","text":"EN → My name is Aniketh Reddy\nFR → Mon nom est \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your english text exit\n"}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}